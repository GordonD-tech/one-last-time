df<-read.csv('https://raw.githubusercontent.com/GordonD-tech/one-last-time/refs/heads/main/Sleep_health_and_lifestyle_dataset.csv')
#LOADING THE LIBRARIES
library(tidymodels) #INCLUDES parsnip PACKAGE FOR decision_tree()
library(caret) #FOR confusionMatrix()

view(df)


##PARTITIONING THE DATA##
set.seed(123)
split1<-initial_split(df, prop=.7, strata=Stress.Level)
train<-training(split1)
holdout<-testing(split1)

set.seed(123)
split2<-initial_split(holdout, prop=.5, strata=Stress.Level)
val<- training(split2)
test<-testing(split2)

training_rows <- runif(dim(df)[1])>.3 #RANDOM VARIABLE THAT IS TRUE 70% OF TIME
training <- df[training_rows,] #PULL TRAINING ROWS
holdout <-df[!training_rows,] #PULL NON TRAINING ROWS

library(sm) #loads library for the next function to work
##BUILD A UNIVARIATE REGRESSION MODEL TO LOOK AT THE EFFECT OF PROMO ON SALES##
M2<-lm(Stress.Level~Quality.of.Sleep, train)  #builds the model: Sales = B_0+B_1(Promo)+e
summary(M2)  #returns summary output from the model M2
M3<-lm(Stress.Level~Quality.of.Sleep, val)  #builds the model: Sales = B_0+B_1(Promo)+e
summary(M3)
library(datasets)
M4<-lm(Stress.Level~log(Quality.of.Sleep), df)  ##level-log model: y=B0+B1*ln(x)+u
summary(M4)
M5<-lm(Stress.Level~log(Quality.of.Sleep), train)  
M6<-lm(Stress.Level~log(Quality.of.Sleep), val)
library(tidyverse)

#STEP 1: FORM THE INPUT MATRIX X:

#STEP 1.1: MAKE A COLUMN OF ONES TO INCLUDE AS REGRESSORS FOR INTERCEPT
col_of_ones <- rep(1, dim(train)[1])

#STEP 1.2: BIND COLUMN OF ONES WITH OTHER INPUT DATA COLUMNS
#AND COERCE TO MATRIX OBJECT
X <- as.matrix(cbind(col_of_ones, train[,-c(1,2,4,9,10,13)]))

#STEP 2: FORM THE OUTPUT VECTOR y
y <- train[,8]

#STEP 3: COMPUTE THE PSEUDOINVERSE MATRIX
X_pseudo <- solve(t(X)%*%X)%*%t(X)

#STEP 4: MULTIPLY THE PSEUDOINVERSE MATRIX BY THE OUTPUT VECTOR
Betas <- X_pseudo%*%y

#CREATE INPUT MATRIX FOR HOLDOUT PARTITION
X_holdout <- as.matrix(cbind(col_of_ones[1:dim(holdout)[1]], holdout[,-c(1,2,4,9,10,13)]))

PRED_OUT <- X_holdout%*%Betas

y_holdout <- df[!training_rows,8]
#SET UP GRID OF REGULARIZATION PARAMETER (LAMBDA) VALUES
lambda <- seq(0, 2,.001)
#INITIALIZE EMPTY MATRIX TO STORE ESTIMATED MODEL COEFFICIENTS FOR EACH LAMBDA
BETA_RIDGE <- matrix(NA, nrow = dim(t(X)%*%X) [1], ncol = length(lambda))
#INITIALIZE EMPTY MATRICES FOR STORING PREDICTION AND ERRORS
PRED_IN <- matrix(NA, nrow = dim(train) [1], ncol = length(lambda))
PRED_OUT <- matrix(NA, nrow = dim(holdout) [1], ncol = length (lambda))
E_IN <- matrix(NA, nrow = 1, ncol=length(lambda))
E_OUT <- matrix(NA, nrow = 1, ncol = length(lambda))

for (i in 1: length(lambda)){
  #COMPUTE PSEUDOINVERSE SOLUTION
  BETA_RIDGE[,i] <- solve(t(X)%*%X+lambda[i]*diag(dim(t(X)%*%X)[1]))%*%t(X)%*%y
  
  #COMPUTE PREDICTIONS IN AND OUT-OF-SAMPLE
  PRED_IN[,i] <- X%*%BETA_RIDGE[,i]
  PRED_OUT[,i] <- X_holdout%*%BETA_RIDGE[,i]
  
  #COMPUTE PREDICTION ERRORS (MSE) IN AND OUT-OF-SAMPLE
  E_IN[i] <- sqrt(mean((y-PRED_IN[,i])^2))
  E_OUT[i] <- sqrt(mean((y_holdout-PRED_OUT[,i])^2))
}
#STORE ERRORS VS. LAMBDAS IN SEPARATE DATAFRAMES
df_IN <- data.frame(cbind(Error=as.numeric(E_IN), Lambda=lambda))
df_OUT <- data.frame(cbind(Error=as.numeric(E_OUT), Lambda=lambda))
#REPORT MINIMUM E_OUT ESTIMATE FROM BEST REGULARIZED MODEL
(min(df_OUT$Error))
#RECOVER OPTIMAL LAMBDA
(Opt_Lambda <- df_OUT$Lambda[which.min(df_OUT$Error)])

library(broom) #FOR tidy() AND glance()
library(MASS) #FOR lm.ridge()
library(lmridge) #FOR lmridge()
#LOADING LIBRARIES
library(vtreat) #FOR kWayCrossValidation()
library(Metrics) #FOR rmse()


glm.qpois<-glm(Stress.Level ~ Quality.of.Sleep, data = df, family = quasipoisson())
summary(glm.qpois)

log.glm.qpois<-glm(Stress.Level ~ log(Quality.of.Sleep), data = df, family = quasipoisson())
summary(log.glm.qpois)

plot(df$Stress.Level ~ df$Quality.of.Sleep) #REMIND OURSELVES WHAT THIS LOOKS LIKE

#build the model with the training partition
M.1qpois<-glm(Stress.Level ~ Quality.of.Sleep, data = train, family = quasipoisson())
summary(M.1qpois)
M.1logqpois<-glm(Stress.Level ~ log(Quality.of.Sleep), data = train, family = quasipoisson())
summary(M.1logqpois)
M.2qpois<-glm(Stress.Level ~ Quality.of.Sleep, data = holdout, family = quasipoisson())
summary(M.2qpois)
M.2logqpois<-glm(Stress.Level ~ log(Quality.of.Sleep), data = holdout, family = quasipoisson())
summary(M.2logqpois)
plot(train$Stress.Level ~ train$Quality.of.Sleep)
plot(holdout$Stress.Level ~ holdout$Quality.of.Sleep)

##LOAD LIBRARIES
library(tidyverse) #includes dplyr and ggplot2
library(tseries) #for the J-B test
library(ggthemes) #for pre-loaded themes for ggplot2

##ADD A (LINEAR) SMOOTHER  AND SOME FORMATTING TO THE SCATTER
plot(train$Stress.Level, train$Quality.of.Sleep, type = "l", col = "blue", ylim = range(c(train$Quality.of.Sleep, holdout$Quality.of.Sleep)), 
     xlab = "Stress Levels", ylab = "Quality of Sleep", main = "How Stress Levels Affects Quality of Sleep")
lines(holdout$Stress.Level, holdout$Quality.of.Sleep, col = "red", lty = 2)
legend("topright", legend = c("Train", "Holdout"), col = c("blue", "red"), lty = c(1, 2))

model <- lm(Quality.of.Sleep ~ Stress.Level, data = holdout)

# Combine for consistent x-axis scaling
x_min <- 0
x_max <- 12
y_min <- 0
y_max <- 12

plot(train$Stress.Level, train$Quality.of.Sleep, type = "p", col = "blue", 
     xlab = "Stress Level", ylab = "Quality of Sleep", 
     main = "How Stress Levels Affects Quality of Sleep", 
     ylim = range(c(train$Quality.of.Sleep, holdout$Quality.of.Sleep)))
abline(a = y_max, b = -(y_max - y_min) / (x_max - x_min), col = "red", lwd = 2)

#4f: RMSE
sqrt(mean(residuals(M.1qpois)^2))
sqrt(mean(residuals(M.2qpois)^2))
sqrt(mean(residuals(M.logqpois)^2))
sqrt(mean(residuals(M.2logqpois)^2))

model_names <- c("Linear", 
                 "Log-Linear", 
                 "Ridge (Î» = 0)", 
                 "Poisson (Linear)", 
                 "Poisson (Log)")

in_sample_rmse <- c(0.7517, 
                    sqrt(mean(residuals(M5)^2)), 
                    NA,        # Optional: ridge in-sample not calculated
                    0.3492, 
                    0.3989)

out_sample_rmse <- c(0.696, 
                     sqrt(mean(residuals(M6)^2)), 
                     7.69e-13, 
                     0.3003, 
                     0.3170)

results_table <- data.frame(Model = model_names,
                            In_Sample_RMSE = in_sample_rmse,
                            Out_of_Sample_RMSE = out_sample_rmse)

print(results_table)

cat("Best model based on out-of-sample RMSE is: Poisson (Linear)\n")

final_model <- glm(Stress.Level ~ Quality.of.Sleep, data = train, family = quasipoisson())
test_rmse <- sqrt(mean(residuals(glm(Stress.Level ~ Quality.of.Sleep, data = test, family = quasipoisson()))^2))

cat("Uncontaminated test RMSE for final model (Poisson Linear):", test_rmse, "\n")

# Creates a linear model fit to training data with 
# dummy variables "Gender, Occupation, BMI Catagory" 

model_lm <- lm(Stress.Level ~ Sleep.Duration + Age + Gender + Occupation + BMI.Category,
               data = train)

summary(model_lm)

# Predict on training and validation data sets
pred_train <- predict(model_lm, newdata = train)
pred_val <- predict(model_lm, newdata = val)

# In-sample RMSE (training set)
rmse_train <- sqrt(mean((train$Stress.Level - pred_train)^2))

# Out-of-sample RMSE (validation set)
rmse_val <- sqrt(mean((val$Stress.Level - pred_val)^2))

cat("In-sample RMSE:", rmse_train, "\n")
cat("Out-of-sample RMSE:", rmse_val, "\n")

