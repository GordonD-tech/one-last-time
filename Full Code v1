# Load libraries
library(tidymodels)
library(caret)
library(MASS)
library(lmridge)
library(Metrics)
library(tidyverse)
library(tseries)
library(ggthemes)
library(ggplot2)
library(glmnet)  # For Elastic Net
library(baguette) #FOR BAGGED TREES
library(ranger) #FOR RANDOM FORESTS
library(randomForest) #ALT RANDOM FOREST PACKAGE
library(xgboost) #FOR GRADIENT BOOSTING
library(vip) #FOR VARIABLE IMPORTANCE

# Load dataset
df <- read.csv('https://raw.githubusercontent.com/GordonD-tech/one-last-time/refs/heads/main/Sleep_health_and_lifestyle_dataset.csv')

# Check correlation
cor_matrix <- cor(df[, sapply(df, is.numeric)], use = "complete.obs")
print(cor_matrix["Stress.Level", ])

# Load SVM library
library(e1071)

# Re-factor entire dataset first to capture all levels
df$Gender <- as.factor(df$Gender)
df$Occupation <- as.factor(df$Occupation)
df$BMI.Category <- as.factor(df$BMI.Category)

# Partition data
set.seed(123)
split1 <- initial_split(df, prop = 0.7, strata = Stress.Level)
train <- training(split1)
holdout <- testing(split1)
split2 <- initial_split(holdout, prop = 0.5, strata = Stress.Level)
val <- training(split2)
test <- testing(split2)

# Load required package
library(pscl)

# Linear Models
M1 <- lm(Stress.Level ~ Quality.of.Sleep, train)
M2 <- lm(Stress.Level ~ log(Quality.of.Sleep), train)
M3 <- lm(Stress.Level ~ Quality.of.Sleep, val)
M4 <- lm(Stress.Level ~ log(Quality.of.Sleep), val)

# Quasipoisson Models
M1_qpois <- glm(Stress.Level ~ Quality.of.Sleep, data = train, family = quasipoisson())
M2_qpois <- glm(Stress.Level ~ log(Quality.of.Sleep), data = train, family = quasipoisson())
M3_qpois <- glm(Stress.Level ~ Quality.of.Sleep, data = val, family = quasipoisson())
M4_qpois <- glm(Stress.Level ~ log(Quality.of.Sleep), data = val, family = quasipoisson())


# Linear Models (R-squared from summary)
rsq_M1 <- summary(M1)$r.squared
rsq_M2 <- summary(M2)$r.squared
rsq_M3 <- summary(M3)$r.squared
rsq_M4 <- summary(M4)$r.squared

# Fit Poisson models
M1_pois <- glm(Stress.Level ~ Quality.of.Sleep, data = train, family = poisson())
M2_pois <- glm(Stress.Level ~ log(Quality.of.Sleep), data = train, family = poisson())
M3_pois <- glm(Stress.Level ~ Quality.of.Sleep, data = val, family = poisson())
M4_pois <- glm(Stress.Level ~ log(Quality.of.Sleep), data = val, family = poisson())

# McFadden's pseudo R² from Poisson models
pseudo_M1 <- 1 - logLik(M1_pois) / logLik(update(M1_pois, . ~ 1))
pseudo_M2 <- 1 - logLik(M2_pois) / logLik(update(M2_pois, . ~ 1))
pseudo_M3 <- 1 - logLik(M3_pois) / logLik(update(M3_pois, . ~ 1))
pseudo_M4 <- 1 - logLik(M4_pois) / logLik(update(M4_pois, . ~ 1))

# Linear model R² from summary
rsq_M1 <- summary(M1)$r.squared
rsq_M2 <- summary(M2)$r.squared
rsq_M3 <- summary(M3)$r.squared
rsq_M4 <- summary(M4)$r.squared

# Build results table
rsq_table <- data.frame(
  Model = c("Linear (Train)", "Log-Linear (Train)", "Linear (Val)", "Log-Linear (Val)",
            "Poisson Linear (Train)", "Poisson Log (Train)", "Poisson Linear (Val)", "Poisson Log (Val)"),
  R_Squared = round(c(rsq_M1, rsq_M2, rsq_M3, rsq_M4,
                      as.numeric(pseudo_M1),
                      as.numeric(pseudo_M2),
                      as.numeric(pseudo_M3),
                      as.numeric(pseudo_M4)), 4)
)

print(rsq_table)

# Create combined summary table with R-squared and RMSE
model_summary <- data.frame(
  Model = c("Linear", "Log-Linear", "Poisson Linear", "Poisson Log"),
  
  Train_R_Squared = round(c(rsq_M1, rsq_M2, as.numeric(pseudo_M1), as.numeric(pseudo_M2)), 4),
  Val_R_Squared   = round(c(rsq_M3, rsq_M4, as.numeric(pseudo_M3), as.numeric(pseudo_M4)), 4),
  
  Train_RMSE      = round(c(rmse_M1, rmse_M2, rmse_M1_qpois, rmse_M2_qpois), 4),
  Val_RMSE        = round(c(rmse_M3, rmse_M4, rmse_M3_qpois, rmse_M4_qpois), 4)
)

# View the summary table
print(model_summary)



# Overlay fits
ggplot(train, aes(x = Quality.of.Sleep, y = Stress.Level)) +
  geom_point(color = "black") +
  stat_smooth(method = "lm", se = FALSE, aes(color = "Linear")) +
  stat_smooth(method = "lm", formula = y ~ log(x), se = FALSE, aes(color = "Log")) +
  geom_line(aes(y = predict(M1_qpois, type = "response"), color = "Poisson Linear")) +
  geom_line(aes(y = predict(M2_qpois, type = "response"), color = "Poisson Log")) +
  labs(title = "Model Fits on Training Set", x = "Quality of Sleep", y = "Stress Level") +
  scale_color_manual(values = c("Linear" = "blue", "Log" = "green", "Poisson Linear" = "purple", "Poisson Log" = "orange")) +
  theme_minimal()


# Multivariate Models #######################################

# ---- MODEL DEFINITIONS ----
# Multivariate Linear Model
model_lm <- lm(Stress.Level ~ Sleep.Duration + Age + Gender + Occupation + BMI.Category, data = train)
model_nl <- lm(Stress.Level ~ poly(Sleep.Duration, 2) + log(Age + 1) + Gender + Occupation + BMI.Category, data = train)

# Elastic Net
combined <- rbind(train, val, test)
X_all <- model.matrix(Stress.Level ~ poly(Sleep.Duration, 2) + log(Age + 1) + Gender + Occupation + BMI.Category, data = combined)[, -1]
y_all <- combined$Stress.Level
X_trainval <- X_all[1:(nrow(train) + nrow(val)), ]
y_trainval <- y_all[1:(nrow(train) + nrow(val))]
X_test <- X_all[(nrow(train) + nrow(val) + 1):nrow(combined), ]
y_test <- test$Stress.Level
cv_model <- cv.glmnet(X_trainval, y_trainval, alpha = 0.5)
best_lambda_enet <- cv_model$lambda.min

# SVM
library(e1071)
svm_model <- svm(Stress.Level ~ Sleep.Duration + Age + Gender + Occupation + BMI.Category, data = train,
                 kernel = "radial", cost = 1, epsilon = 0.1)

# Tuned SVM
library(tidymodels)
tune_result <- tune(
  svm,
  Stress.Level ~ Sleep.Duration + Age + Gender + Occupation + BMI.Category,
  data = train,
  ranges = list(cost = c(0.1, 1, 10, 100), gamma = c(0.01, 0.1, 1), epsilon = c(0.01, 0.1, 0.5))
)
best_svm <- tune_result$best.model

# Regression Tree
reg_spec <- decision_tree(min_n = 20, tree_depth = 30, cost_complexity = 0.01) %>%
  set_engine("rpart") %>% set_mode("regression")
reg_tree <- reg_spec %>% fit(Stress.Level ~ ., data = train)

# Random Forest
rf_spec <- rand_forest(mode = "regression", mtry = 3, trees = 500, min_n = 5) %>%
  set_engine("ranger")
rf_model <- rf_spec %>% fit(Stress.Level ~ ., data = train)

# Tuned Random Forest
rf_tune_spec <- rand_forest(mode = "regression", mtry = tune(), min_n = tune(), trees = 500) %>%
  set_engine("ranger")
rf_wf <- workflow() %>% add_model(rf_tune_spec) %>% add_formula(Stress.Level ~ .)
cv_folds <- vfold_cv(train, v = 5)
rf_grid <- grid_random(mtry(range = c(1, ncol(train) - 1)), min_n(range = c(2, 20)), size = 20)
tuned_results <- tune_grid(rf_wf, resamples = cv_folds, grid = rf_grid, metrics = metric_set(rmse))
best_params <- select_best(tuned_results, metric = "rmse")
final_rf <- finalize_workflow(rf_wf, best_params)
final_model <- fit(final_rf, data = train)

# ---- PREDICTIONS & METRICS ----
predict_metrics <- function(model, train_data, val_data, truth) {
  pred_train <- predict(model, newdata = train_data)
  pred_val <- predict(model, newdata = val_data)
  rmse_train <- sqrt(mean((train_data[[truth]] - pred_train)^2))
  rmse_val <- sqrt(mean((val_data[[truth]] - pred_val)^2))
  rsq_train <- cor(train_data[[truth]], pred_train)^2
  rsq_val <- cor(val_data[[truth]], pred_val)^2
  return(list(rmse_train = rmse_train, rmse_val = rmse_val, rsq_train = rsq_train, rsq_val = rsq_val))
}

# Gather metrics for each model
lm_metrics <- predict_metrics(model_lm, train, val, "Stress.Level")
nl_metrics <- predict_metrics(model_nl, train, val, "Stress.Level")
svm_metrics <- predict_metrics(svm_model, train, val, "Stress.Level")
tuned_svm_metrics <- predict_metrics(best_svm, train, val, "Stress.Level")
tree_metrics <- predict_metrics(reg_tree, train, val, "Stress.Level")
rf_metrics <- predict_metrics(rf_model, train, val, "Stress.Level")
final_rf_metrics <- predict_metrics(final_model, train, val, "Stress.Level")

# Elastic net custom metrics
pred_enet_train <- predict(cv_model, s = best_lambda_enet, newx = X_trainval)
pred_enet_val <- predict(cv_model, s = best_lambda_enet, newx = model.matrix(Stress.Level ~ poly(Sleep.Duration, 2) + log(Age + 1) + Gender + Occupation + BMI.Category, data = val)[, -1])
in_rmse_enet <- sqrt(mean((y_trainval - pred_enet_train)^2))
val_rmse_enet <- sqrt(mean((val$Stress.Level - pred_enet_val)^2))
rsq_train_enet <- cor(y_trainval, as.numeric(pred_enet_train))^2
rsq_val_enet <- cor(val$Stress.Level, as.numeric(pred_enet_val))^2

# ---- BUILD FINAL TABLE ----
final_perf_table <- tibble(
  Model = c("Multivariate Linear", "Multivariate Nonlinear", "Elastic Net", "SVM", "Tuned SVM", "Regression Tree", "Tuned Random Forest"),
  Train_RMSE = round(c(lm_metrics$rmse_train, nl_metrics$rmse_train, in_rmse_enet, svm_metrics$rmse_train, tuned_svm_metrics$rmse_train, tree_metrics$rmse_train, final_rf_metrics$rmse_train), 4),
  Val_RMSE = round(c(lm_metrics$rmse_val, nl_metrics$rmse_val, val_rmse_enet, svm_metrics$rmse_val, tuned_svm_metrics$rmse_val, tree_metrics$rmse_val, final_rf_metrics$rmse_val), 4),
  Train_R_Squared = round(c(lm_metrics$rsq_train, nl_metrics$rsq_train, rsq_train_enet, svm_metrics$rsq_train, tuned_svm_metrics$rsq_train, tree_metrics$rsq_train, final_rf_metrics$rsq_train), 4),
  Val_R_Squared = round(c(lm_metrics$rsq_val, nl_metrics$rsq_val, rsq_val_enet, svm_metrics$rsq_val, tuned_svm_metrics$rsq_val, tree_metrics$rsq_val, final_rf_metrics$rsq_val), 4)
)

# Print final comparison
print(final_perf_table)

# Predict on test set using the final tuned random forest model
test_preds_rf <- predict(final_model, new_data = test) %>%
  bind_cols(data.frame(Stress.Level = test$Stress.Level))

# Calculate RMSE on test set
test_rmse_rf <- test_preds_rf %>%
  metrics(truth = Stress.Level, estimate = .pred) %>%
  filter(.metric == "rmse") %>%
  pull(.estimate)

# Calculate R-squared on test set
test_rsq_rf <- cor(test_preds_rf$Stress.Level, test_preds_rf$.pred)^2

# Display results
cat("\n Final model tested on unseen data (Test Set)\n")
cat("Test RMSE:", round(test_rmse_rf, 4), "\n")
cat("Test R-squared:", round(test_rsq_rf, 4), "\n")

# Optional: Create a tidy summary table
final_test_summary <- tibble(
  Model = "Tuned Random Forest",
  Test_RMSE = round(test_rmse_rf, 4),
  Test_R_Squared = round(test_rsq_rf, 4)
)

print(final_test_summary)

# Task #6, Classification #######################################
# Changing stess level to catagorical variable (Stress.Category)
library(dplyr)

df <- df %>%
  mutate(Stress.Category = case_when(
    Stress.Level < 6  ~ "Low",
    Stress.Level == 6 ~ "Average",
    Stress.Level > 6  ~ "High"
  ))

df <- df %>%
  mutate(Stress.Category = factor(Stress.Category, levels = c("Low", "Average", "High")))

library(tidymodels)

# Partition data using Stress.Category for stratified sampling
set.seed(123)
split1 <- initial_split(df, prop = 0.7, strata = Stress.Category)
train <- training(split1)
holdout <- testing(split1)

split2 <- initial_split(holdout, prop = 0.5, strata = Stress.Category)
val <- training(split2)
test <- testing(split2)

# Load MASS package for ordinal logistic regression
library(MASS)
# Install pROC if not already installed
install.packages("pROC")

# Load the package
library(pROC)

# 1. Find the most common (majority) class in the training set
majority_class <- names(sort(table(train$Stress.Category), decreasing = TRUE))[1]
cat("Majority class is:", majority_class, "\n")

# 2. Predict the majority class for every observation in the validation set
baseline_preds <- factor(rep(majority_class, nrow(val)),
                         levels = levels(val$Stress.Category))

# 3. Calculate accuracy of baseline model
baseline_accuracy <- mean(baseline_preds == val$Stress.Category)
cat("Baseline model accuracy (always predicts", majority_class, "):", baseline_accuracy, "\n")

# Probit model
probit_model <- glm(Stress.Category ~ Quality.of.Sleep + Age + Physical.Activity.Level, 
                    data = train, 
                    family = binomial(link = "probit"))

# Fit ordinal logistic regression model with multiple numeric variables
ord_logit_model_activity <- polr(
  Stress.Category ~ Quality.of.Sleep + Age + Physical.Activity.Level + Sleep.Duration,
  data = train,
  Hess = TRUE
)

# View model summary
summary(ord_logit_model_activity)
summary(probit_model)

# Predict on validation set
val_preds_activity <- predict(ord_logit_model_activity, newdata = val)
val_preds_activity_probit <- predict(probit_model, newdata = val)

# Compute AUC
roc_logit <- roc(Stress.Category, ord_logit_model_activity)
roc_probit <- roc(Stress.Category, probit_model)

auc(roc_logit)
auc(roc_probit)

# Optional: Plot ROC curves
plot(roc_logit, col = "blue", main = "ROC Curves: Logit vs Probit")
lines(roc_probit, col = "red")
legend("bottomright", legend = c("Logit", "Probit"), col = c("blue", "red"), lwd = 2)

# Accuracy
mean(val_preds_activity == val$Stress.Category)
#confusion Matrix
table(Predicted = val_preds_activity, Actual = val$Stress.Category)

# Try with fewer predictors to test convergence
ord_logit_model_simple <- polr(Stress.Category ~ Quality.of.Sleep + Age + Sleep.Duration,
                               data = train,
                               Hess = TRUE)

summary(ord_logit_model_simple)

# Predict on validation set
val_preds <- predict(ord_logit_model_simple, newdata = val)

# Define SVM model
svm_spec <- svm_rbf(mode = "classification") %>%
  set_engine("kernlab")

# Fit the model
svm_fit <- workflow() %>%
  add_model(svm_spec) %>%
  add_formula(Stress.Category ~ Quality.of.Sleep + Age + Physical.Activity.Level + Sleep.Duration) %>%
  fit(data = train)

# In-sample prediction for SVM
train_preds <- predict(svm_fit, new_data = train) %>%
  bind_cols(train %>% select(Stress.Category))

# Out-of-sample (validation set) prediction for SVM
val_preds <- predict(svm_fit, new_data = val) %>%
  bind_cols(val %>% select(Stress.Category))

# Accuracy for SVM
train_acc <- train_preds %>%
  metrics(truth = Stress.Category, estimate = .pred_class) %>%
  filter(.metric == "accuracy")

val_acc <- val_preds %>%
  metrics(truth = Stress.Category, estimate = .pred_class) %>%
  filter(.metric == "accuracy")

# Define SVM model with tuning
svm_tune_spec <- svm_rbf(
  mode = "classification",
  cost = tune(),
  rbf_sigma = tune()
) %>%
  set_engine("kernlab")

# Create SVM workflow
svm_workflow <- workflow() %>%
  add_model(svm_tune_spec) %>%
  add_formula(Stress.Category ~ Quality.of.Sleep + Age + Physical.Activity.Level + Sleep.Duration)

# Define tuning grid
svm_grid <- grid_regular(cost(), rbf_sigma(), levels = 5)

# Perform tuning
set.seed(123)
svm_res <- tune_grid(
  svm_workflow,
  resamples = vfold_cv(train, v = 5, strata = Stress.Category),
  grid = svm_grid,
  metrics = metric_set(accuracy)
)

# Select best parameters
best_svm <- select_best(svm_res, "accuracy")

# Finalize model with best parameters
final_svm <- finalize_workflow(svm_workflow, best_svm) %>%
  fit(data = train)

# Predict on validation set with tuned model
val_preds_tuned <- predict(final_svm, new_data = val) %>%
  bind_cols(val %>% select(Stress.Category))

val_acc_tuned <- val_preds_tuned %>%
  metrics(truth = Stress.Category, estimate = .pred_class) %>%
  filter(.metric == "accuracy")

# Accuracy
mean(val_preds == val$Stress.Category)
#confusion Matrix
table(Predicted = val_preds, Actual = val$Stress.Category)
####*****Classification Tree#########
# Define recipe
tree_rec <- recipe(Stress.Category ~ ., data = train_data) %>%
  step_dummy(all_nominal_predictors()) %>%  # if needed
  step_zv(all_predictors())                 # remove zero variance

# Classification tree model
tree_mod <- decision_tree(mode = "classification") %>%
  set_engine("rpart")

# Workflow
tree_wf <- workflow() %>%
  add_model(tree_mod) %>%
  add_recipe(tree_rec)

# Fit to training data
tree_fit <- tree_wf %>% fit(data = train_data)

# Predict on training
train_preds <- predict(tree_fit, train_data, type = "class") %>%
  bind_cols(train_data)

# Predict on test
test_preds <- predict(tree_fit, test_data, type = "class") %>%
  bind_cols(test_data)

# Evaluate in-sample and out-of-sample
train_metrics <- train_preds %>%
  metrics(truth = Stress.Category, estimate = .pred_class)

test_metrics <- test_preds %>%
  metrics(truth = Stress.Category, estimate = .pred_class)

print(train_metrics)
print(test_metrics)

# Extract tree for plotting
tree_model <- extract_fit_parsnip(tree_fit)$fit
rpart.plot(tree_model)

# Model with tuning
tree_mod_tuned <- decision_tree(
  mode = "classification",
  cost_complexity = tune(),
  tree_depth = tune()
) %>% set_engine("rpart")

# Workflow
tree_wf_tuned <- workflow() %>%
  add_model(tree_mod_tuned) %>%
  add_recipe(tree_rec)

# 5-fold CV
tree_folds <- vfold_cv(train_data, v = 5, strata = Stress.Category)

# Grid search
tree_grid <- grid_regular(
  cost_complexity(),
  tree_depth(),
  levels = 5
)

# Tuning
tree_tune_res <- tune_grid(
  tree_wf_tuned,
  resamples = tree_folds,
  grid = tree_grid,
  metrics = metric_set(accuracy, roc_auc)
)

# Best model
best_tree <- select_best(tree_tune_res, "accuracy")
final_tree <- finalize_workflow(tree_wf_tuned, best_tree)
final_fit <- final_tree %>% fit(train_data)

# Final test set predictions
final_preds <- predict(final_fit, test_data, type = "class") %>%
  bind_cols(test_data)

final_metrics <- final_preds %>%
  metrics(truth = Stress.Category, estimate = .pred_class)

print(final_metrics)


####Tree Model####
# Recipe
rf_rec <- recipe(Stress.Category ~ ., data = train_data) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())

# Model (initial, untuned)
rf_mod <- rand_forest(mode = "classification") %>%
  set_engine("ranger")

# Workflow
rf_wf <- workflow() %>%
  add_recipe(rf_rec) %>%
  add_model(rf_mod)

# Fit model to training data
rf_fit <- rf_wf %>% fit(data = train_data)

# Predictions
train_preds_rf <- predict(rf_fit, train_data, type = "class") %>%
  bind_cols(train_data)

test_preds_rf <- predict(rf_fit, test_data, type = "class") %>%
  bind_cols(test_data)

# Accuracy and ROC AUC
train_metrics_rf <- train_preds_rf %>%
  metrics(truth = Stress.Category, estimate = .pred_class)

test_metrics_rf <- test_preds_rf %>%
  metrics(truth = Stress.Category, estimate = .pred_class)

print(train_metrics_rf)
print(test_metrics_rf)

# Model with tuning parameters
rf_mod_tuned <- rand_forest(
  mode = "classification",
  mtry = tune(),
  trees = 500,
  min_n = tune()
) %>% set_engine("ranger")

# Workflow
rf_wf_tuned <- workflow() %>%
  add_recipe(rf_rec) %>%
  add_model(rf_mod_tuned)

# Cross-validation folds
rf_folds <- vfold_cv(train_data, v = 5, strata = Stress.Category)

# Grid search
rf_grid <- grid_regular(
  mtry(range = c(2, 10)),
  min_n(range = c(2, 10)),
  levels = 5
)

# Tune the model
rf_tune_res <- tune_grid(
  rf_wf_tuned,
  resamples = rf_folds,
  grid = rf_grid,
  metrics = metric_set(accuracy, roc_auc)
)

# Get best model by accuracy
best_rf <- select_best(rf_tune_res, "accuracy")

# Final model
final_rf_wf <- finalize_workflow(rf_wf_tuned, best_rf)
final_rf_fit <- final_rf_wf %>% fit(train_data)

# Predict on test set
final_rf_preds <- predict(final_rf_fit, test_data, type = "class") %>%
  bind_cols(test_data)

final_rf_metrics <- final_rf_preds %>%
  metrics(truth = Stress.Category, estimate = .pred_class)

print(final_rf_metrics)

model_names <- c(
  "Logistic Regression",
  "Probit Model",
  "SVM (Untuned)",
  "SVM (Tuned)",
  "Classification Tree",
  "Tree (Tuned)",
  "Random Forest (Untuned)",
  "Random Forest (Tuned)"
)

in_sample <- c(
  acc_logit_train,
  acc_probit_train,
  acc_svm_train,
  acc_svm_tuned_train,
  acc_tree_train,
  acc_tree_tuned_train,
  acc_rf_train,
  acc_rf_tuned_train
)

out_of_sample <- c(
  acc_logit_val,
  acc_probit_val,
  acc_svm_val,
  acc_svm_tuned_val,
  acc_tree_val,
  acc_tree_tuned_val,
  acc_rf_val,
  acc_rf_tuned_val
)

test_performance <- c(
  acc_logit_test,
  acc_probit_test,
  acc_svm_test,
  acc_svm_tuned_test,
  acc_tree_test,
  acc_tree_tuned_test,
  acc_rf_test,
  acc_rf_tuned_test
)

# Create the summary table
performance_table <- tibble(
  Model = model_names,
  In_Sample_Accuracy = round(in_sample, 4),
  Validation_Accuracy = round(out_of_sample, 4),
  Test_Accuracy = round(test_performance, 4)
)

print(performance_table)
