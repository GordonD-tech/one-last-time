# Load libraries
library(tidymodels)
library(caret)
library(MASS)
library(lmridge)
library(Metrics)
library(tidyverse)
library(tseries)
library(ggthemes)
library(ggplot2)
library(glmnet)  # For Elastic Net
library(baguette) #FOR BAGGED TREES
library(ranger) #FOR RANDOM FORESTS
library(randomForest) #ALT RANDOM FOREST PACKAGE
library(xgboost) #FOR GRADIENT BOOSTING
library(vip) #FOR VARIABLE IMPORTANCE

# Load dataset
df <- read.csv('https://raw.githubusercontent.com/GordonD-tech/one-last-time/refs/heads/main/Sleep_health_and_lifestyle_dataset.csv')

# Check correlation
cor_matrix <- cor(df[, sapply(df, is.numeric)], use = "complete.obs")
print(cor_matrix["Stress.Level", ])

# Load SVM library
library(e1071)

# Re-factor entire dataset first to capture all levels
df$Gender <- as.factor(df$Gender)
df$Occupation <- as.factor(df$Occupation)
df$BMI.Category <- as.factor(df$BMI.Category)

# Partition data
set.seed(123)
split1 <- initial_split(df, prop = 0.7, strata = Stress.Level)
train <- training(split1)
holdout <- testing(split1)
split2 <- initial_split(holdout, prop = 0.5, strata = Stress.Level)
val <- training(split2)
test <- testing(split2)

# Load required package
library(pscl)

# Linear Models
M1 <- lm(Stress.Level ~ Quality.of.Sleep, train)
M2 <- lm(Stress.Level ~ log(Quality.of.Sleep), train)
M3 <- lm(Stress.Level ~ Quality.of.Sleep, val)
M4 <- lm(Stress.Level ~ log(Quality.of.Sleep), val)

# Quasipoisson Models
M1_qpois <- glm(Stress.Level ~ Quality.of.Sleep, data = train, family = quasipoisson())
M2_qpois <- glm(Stress.Level ~ log(Quality.of.Sleep), data = train, family = quasipoisson())
M3_qpois <- glm(Stress.Level ~ Quality.of.Sleep, data = val, family = quasipoisson())
M4_qpois <- glm(Stress.Level ~ log(Quality.of.Sleep), data = val, family = quasipoisson())


# Linear Models (R-squared from summary)
rsq_M1 <- summary(M1)$r.squared
rsq_M2 <- summary(M2)$r.squared
rsq_M3 <- summary(M3)$r.squared
rsq_M4 <- summary(M4)$r.squared

# Fit Poisson models
M1_pois <- glm(Stress.Level ~ Quality.of.Sleep, data = train, family = poisson())
M2_pois <- glm(Stress.Level ~ log(Quality.of.Sleep), data = train, family = poisson())
M3_pois <- glm(Stress.Level ~ Quality.of.Sleep, data = val, family = poisson())
M4_pois <- glm(Stress.Level ~ log(Quality.of.Sleep), data = val, family = poisson())

# McFadden's pseudo RÂ² from Poisson models
pseudo_M1 <- 1 - logLik(M1_pois) / logLik(update(M1_pois, . ~ 1))
pseudo_M2 <- 1 - logLik(M2_pois) / logLik(update(M2_pois, . ~ 1))
pseudo_M3 <- 1 - logLik(M3_pois) / logLik(update(M3_pois, . ~ 1))
pseudo_M4 <- 1 - logLik(M4_pois) / logLik(update(M4_pois, . ~ 1))

# Linear model RÂ² from summary
rsq_M1 <- summary(M1)$r.squared
rsq_M2 <- summary(M2)$r.squared
rsq_M3 <- summary(M3)$r.squared
rsq_M4 <- summary(M4)$r.squared

# Build results table
rsq_table <- data.frame(
  Model = c("Linear (Train)", "Log-Linear (Train)", "Linear (Val)", "Log-Linear (Val)",
            "Poisson Linear (Train)", "Poisson Log (Train)", "Poisson Linear (Val)", "Poisson Log (Val)"),
  R_Squared = round(c(rsq_M1, rsq_M2, rsq_M3, rsq_M4,
                      as.numeric(pseudo_M1),
                      as.numeric(pseudo_M2),
                      as.numeric(pseudo_M3),
                      as.numeric(pseudo_M4)), 4)
)

print(rsq_table)

# Create combined summary table with R-squared and RMSE
model_summary <- data.frame(
  Model = c("Linear", "Log-Linear", "Poisson Linear", "Poisson Log"),
  
  Train_R_Squared = round(c(rsq_M1, rsq_M2, as.numeric(pseudo_M1), as.numeric(pseudo_M2)), 4),
  Val_R_Squared   = round(c(rsq_M3, rsq_M4, as.numeric(pseudo_M3), as.numeric(pseudo_M4)), 4),
  
  Train_RMSE      = round(c(rmse_M1, rmse_M2, rmse_M1_qpois, rmse_M2_qpois), 4),
  Val_RMSE        = round(c(rmse_M3, rmse_M4, rmse_M3_qpois, rmse_M4_qpois), 4)
)

# View the summary table
print(model_summary)



# Overlay fits
ggplot(train, aes(x = Quality.of.Sleep, y = Stress.Level)) +
  geom_point(color = "black") +
  stat_smooth(method = "lm", se = FALSE, aes(color = "Linear")) +
  stat_smooth(method = "lm", formula = y ~ log(x), se = FALSE, aes(color = "Log")) +
  geom_line(aes(y = predict(M1_qpois, type = "response"), color = "Poisson Linear")) +
  geom_line(aes(y = predict(M2_qpois, type = "response"), color = "Poisson Log")) +
  labs(title = "Model Fits on Training Set", x = "Quality of Sleep", y = "Stress Level") +
  scale_color_manual(values = c("Linear" = "blue", "Log" = "green", "Poisson Linear" = "purple", "Poisson Log" = "orange")) +
  theme_minimal()


# Multivariate Models #######################################

# ---- MODEL DEFINITIONS ----
# Multivariate Linear Model
model_lm <- lm(Stress.Level ~ Sleep.Duration + Age + Gender + Occupation + BMI.Category, data = train)
model_nl <- lm(Stress.Level ~ poly(Sleep.Duration, 2) + log(Age + 1) + Gender + Occupation + BMI.Category, data = train)

# Elastic Net
combined <- rbind(train, val, test)
X_all <- model.matrix(Stress.Level ~ poly(Sleep.Duration, 2) + log(Age + 1) + Gender + Occupation + BMI.Category, data = combined)[, -1]
y_all <- combined$Stress.Level
X_trainval <- X_all[1:(nrow(train) + nrow(val)), ]
y_trainval <- y_all[1:(nrow(train) + nrow(val))]
X_test <- X_all[(nrow(train) + nrow(val) + 1):nrow(combined), ]
y_test <- test$Stress.Level
cv_model <- cv.glmnet(X_trainval, y_trainval, alpha = 0.5)
best_lambda_enet <- cv_model$lambda.min

# SVM
library(e1071)
svm_model <- svm(Stress.Level ~ Sleep.Duration + Age + Gender + Occupation + BMI.Category, data = train,
                 kernel = "radial", cost = 1, epsilon = 0.1)

# Tuned SVM
library(tidymodels)
tune_result <- tune(
  svm,
  Stress.Level ~ Sleep.Duration + Age + Gender + Occupation + BMI.Category,
  data = train,
  ranges = list(cost = c(0.1, 1, 10, 100), gamma = c(0.01, 0.1, 1), epsilon = c(0.01, 0.1, 0.5))
)
best_svm <- tune_result$best.model

# Regression Tree
reg_spec <- decision_tree(min_n = 20, tree_depth = 30, cost_complexity = 0.01) %>%
  set_engine("rpart") %>% set_mode("regression")
reg_tree <- reg_spec %>% fit(Stress.Level ~ ., data = train)

# Random Forest
rf_spec <- rand_forest(mode = "regression", mtry = 3, trees = 500, min_n = 5) %>%
  set_engine("ranger")
rf_model <- rf_spec %>% fit(Stress.Level ~ ., data = train)

# Tuned Random Forest
rf_tune_spec <- rand_forest(mode = "regression", mtry = tune(), min_n = tune(), trees = 500) %>%
  set_engine("ranger")
rf_wf <- workflow() %>% add_model(rf_tune_spec) %>% add_formula(Stress.Level ~ .)
cv_folds <- vfold_cv(train, v = 5)
rf_grid <- grid_random(mtry(range = c(1, ncol(train) - 1)), min_n(range = c(2, 20)), size = 20)
tuned_results <- tune_grid(rf_wf, resamples = cv_folds, grid = rf_grid, metrics = metric_set(rmse))
best_params <- select_best(tuned_results, metric = "rmse")
final_rf <- finalize_workflow(rf_wf, best_params)
final_model <- fit(final_rf, data = train)

# ---- PREDICTIONS & METRICS ----
predict_metrics <- function(model, train_data, val_data, truth) {
  pred_train <- predict(model, newdata = train_data)
  pred_val <- predict(model, newdata = val_data)
  rmse_train <- sqrt(mean((train_data[[truth]] - pred_train)^2))
  rmse_val <- sqrt(mean((val_data[[truth]] - pred_val)^2))
  rsq_train <- cor(train_data[[truth]], pred_train)^2
  rsq_val <- cor(val_data[[truth]], pred_val)^2
  return(list(rmse_train = rmse_train, rmse_val = rmse_val, rsq_train = rsq_train, rsq_val = rsq_val))
}

# Gather metrics for each model
lm_metrics <- predict_metrics(model_lm, train, val, "Stress.Level")
nl_metrics <- predict_metrics(model_nl, train, val, "Stress.Level")
svm_metrics <- predict_metrics(svm_model, train, val, "Stress.Level")
tuned_svm_metrics <- predict_metrics(best_svm, train, val, "Stress.Level")
tree_metrics <- predict_metrics(reg_tree, train, val, "Stress.Level")
rf_metrics <- predict_metrics(rf_model, train, val, "Stress.Level")
final_rf_metrics <- predict_metrics(final_model, train, val, "Stress.Level")

# Elastic net custom metrics
pred_enet_train <- predict(cv_model, s = best_lambda_enet, newx = X_trainval)
pred_enet_val <- predict(cv_model, s = best_lambda_enet, newx = model.matrix(Stress.Level ~ poly(Sleep.Duration, 2) + log(Age + 1) + Gender + Occupation + BMI.Category, data = val)[, -1])
in_rmse_enet <- sqrt(mean((y_trainval - pred_enet_train)^2))
val_rmse_enet <- sqrt(mean((val$Stress.Level - pred_enet_val)^2))
rsq_train_enet <- cor(y_trainval, as.numeric(pred_enet_train))^2
rsq_val_enet <- cor(val$Stress.Level, as.numeric(pred_enet_val))^2

# ---- BUILD FINAL TABLE ----
final_perf_table <- tibble(
  Model = c("Multivariate Linear", "Multivariate Nonlinear", "Elastic Net", "SVM", "Tuned SVM", "Regression Tree", "Tuned Random Forest"),
  Train_RMSE = round(c(lm_metrics$rmse_train, nl_metrics$rmse_train, in_rmse_enet, svm_metrics$rmse_train, tuned_svm_metrics$rmse_train, tree_metrics$rmse_train, final_rf_metrics$rmse_train), 4),
  Val_RMSE = round(c(lm_metrics$rmse_val, nl_metrics$rmse_val, val_rmse_enet, svm_metrics$rmse_val, tuned_svm_metrics$rmse_val, tree_metrics$rmse_val, final_rf_metrics$rmse_val), 4),
  Train_R_Squared = round(c(lm_metrics$rsq_train, nl_metrics$rsq_train, rsq_train_enet, svm_metrics$rsq_train, tuned_svm_metrics$rsq_train, tree_metrics$rsq_train, final_rf_metrics$rsq_train), 4),
  Val_R_Squared = round(c(lm_metrics$rsq_val, nl_metrics$rsq_val, rsq_val_enet, svm_metrics$rsq_val, tuned_svm_metrics$rsq_val, tree_metrics$rsq_val, final_rf_metrics$rsq_val), 4)
)

# Print final comparison
print(final_perf_table)

# Predict on test set using the final tuned random forest model
test_preds_rf <- predict(final_model, new_data = test) %>%
  bind_cols(data.frame(Stress.Level = test$Stress.Level))

# Calculate RMSE on test set
test_rmse_rf <- test_preds_rf %>%
  metrics(truth = Stress.Level, estimate = .pred) %>%
  filter(.metric == "rmse") %>%
  pull(.estimate)

# Calculate R-squared on test set
test_rsq_rf <- cor(test_preds_rf$Stress.Level, test_preds_rf$.pred)^2

# Display results
cat("\nâœ… Final model tested on unseen data (Test Set)\n")
cat("ðŸ“‰ Test RMSE:", round(test_rmse_rf, 4), "\n")
cat("ðŸ“ˆ Test R-squared:", round(test_rsq_rf, 4), "\n")

# Optional: Create a tidy summary table
final_test_summary <- tibble(
  Model = "Tuned Random Forest",
  Test_RMSE = round(test_rmse_rf, 4),
  Test_R_Squared = round(test_rsq_rf, 4)
)

print(final_test_summary)
